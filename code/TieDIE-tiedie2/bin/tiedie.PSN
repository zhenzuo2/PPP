#!/usr/bin/env python2.7

###
### TieDIE: Tied Diffusion for Network Discovery
###
###	Version: 
###
###		Multiple (>= 3 inputs) Development Version
###
###	Authors: 
###
###		Evan Paull (epaull@soe.ucsc.edu)
###
###	Requirements:
###
### 	python 2.7.X
###		numpy 1.7+ (with pre-computed kernels)
###		scipy 0.12+ (for on-the-fly kernel generation)
###
### Minimum Inputs: 
###		
###		- separate source/target input heat files: tab-separated, 3 columns each with <gene> <input heat> <sign (+/-)>
###		- a search pathway in .sif format (geneA <interaction> geneB)
###
### Outputs:
###
###		Creates a directory in the current working directory, and writes all output to that
###		Information and warnings are logged to standard error


import os, sys
from collections import defaultdict
from optparse import OptionParser
parser = OptionParser()
parser.add_option("-k","--kernel",dest="kernel",action="store",type="string",default=None,help="\
Pre-computed heat diffusion kernel in tab-delimited form. Should have both a header and row labels. \
The program will attempt to use scipy to generate a kernel if none is supplied.")
parser.add_option("-n","--network",dest="network",action="store",default=None,help="\
.sif network file for the curated pathway to search. <source>   <(-a>,-a|,-t>,-t|,-component>)> <target>")
parser.add_option("-s","--size",dest="size",action="store",default=1,type="float",help="\
Network size control factor (default 1)")
# data specific for patient-specific networks here
parser.add_option("--p_expr",dest="p_expr",action="store",default=None,type="string",help="\
Normal-subtracted Gene Expression Matrix, rows = Genes, columns = Samples")
parser.add_option("--p_mut",dest="p_mut",action="store",default=None,type="string",help="\
Matrix of Mutation Calls, per Patient")
parser.add_option("-m","--min_hub",dest="min_hub",action="store",default=10,type="int",help=\
"minimum number of genes in regulon to consider a TF")
# optional: ranked list of heats from a TieDIE concensus network: compute GSEA enrichment for these
parser.add_option("--node_ranks",dest="node_ranks",action="store",default=None,type="string",help=\
"minimum number of genes in regulon to consider a TF")

# optional inputs here:
(opts, args) = parser.parse_args()

# local imports assume the directory structure from github . 
sys.path.append(os.path.dirname(sys.argv[0])+'/../lib')
from kernel import Kernel
import tiedie_util
from tiedie_util import *
from linkers import *
from master_reg import ActivityScores, SSActivityScores
from pathway import Pathway, BasicPathValidator

if opts.kernel is None:
	sys.stderr.write("Warning: No kernel file supplied, will use SCIPY to compute the matrix exponential, t=0.1...\n")
	from kernel_scipy import SciPYKernel

def thresholdEvents(data, threshold):

	filtered = {}
	for event in data:
		if data[event] >= threshold:
			filtered[event] = data[event]

	return filtered

# parse network file: use for input validation if heat nodes are not in network
sys.stderr.write("Parsing Network File..\n")
network = parseNet(opts.network)
network_nodes = getNetworkNodes(network)

out_prefix = "."
output_folder = out_prefix+"/TieDIE.PSN"

if not os.path.exists(output_folder):
	os.mkdir(output_folder)

#
# Diffusion Step:
#	Load the heat diffusion kernel and perform a kernel-multiply, or alternatively use supplied
# 	page-rank diffused vectors
#

if opts.kernel is not None:
	sys.stderr.write("Loading Heat Diffusion Kernel..\n")
	# load a heat diffusion kernel to perform diffusion
	diffuser = Kernel(opts.kernel)
else:
	sys.stderr.write("Using SCIPY to compute the matrix exponential, t=0.1...\n")
	# No kernel supplied: use SCIPY to generate a kernel on the fly, and then use it
	# for subsequent diffusion operations
	diffuser = SciPYKernel(opts.network)

# by convention, the first input should be the mutation data
sample_mut = parseMatrix(opts.p_mut)

# infer activity scores from the TF edges
ssAct = SSActivityScores(network, opts.p_expr, opts.min_hub)
sample_activities = ssAct.getActivities()

# heat scores from the TieDIE Consensus network
tiedie_heat_scores = None
if opts.node_ranks:
	tiedie_heat_scores, signs = parseHeats(opts.node_ranks)

# We can test only those samples with both expression and perturbation data
test_samples = set(sample_mut.keys()).intersection(set(sample_activities.keys()))
sys.stderr.write("Finding networks for "+str(len(test_samples))+" unique samples\n")

# save significance test statistics
stats = open(output_folder+"/network.stats.txt", 'w')
stats.write("\t".join(["Sample", "Enrichment Score (GSEA)", "P-val"])+"\n")

# save matrix of feature scores by sample
# index first by sample ID
sample_heats = {}
features = None

# generate a TieDIE network for each sample 
for sample_id in test_samples:

	mutation_events = thresholdEvents(sample_mut[sample_id], 1)
	mut_heats, mut_signs = normalizeHeats(mutation_events)
	# hardcoded for now: z = 1.5
	tf_events = thresholdEvents(sample_activities[sample_id], 1.5)
	
	tf_heats, tf_signs = normalizeHeats(tf_events)

	input_heats = {}
	diffused_heats = {}
	input_heats['up'] = mut_heats		
	input_heats['down'] = tf_heats		
	diffused_heats['up'] = diffuser.diffuse(mut_heats)
	diffused_heats['down'] = diffuser.diffuse(tf_heats)
	options = {}
	options['size'] = 1.0
	subnet_soln, subnet_soln_nodes, linker_heats, linker_cutoff = extractSubnetwork(network, input_heats, diffused_heats, 1.0, options)
	max_heat_scores = getMaxHeats(len(input_heats), diffused_heats)

	# write out heat averages for this sample
	out = open(output_folder+"/"+sample_id+".linker_heats.txt", 'w')
	# save the heats
	sample_heats[sample_id] = linker_heats.copy()
	for (key, val) in linker_heats.items():
		out.write(key+"\t"+str(val)+"\n")
	out.close()

	# populate feature space with any representative here
	if not features:
		features = linker_heats.keys()

	##
	## write max heats
	##
	out = open(output_folder+"/"+sample_id+".max_heats.txt", 'w')
	# save the heats
	for (key, val) in max_heat_scores.items():
		out.write(key+"\t"+str(val)+"\n")
	out.close()

	# take the geometric mean of the patient-specific scores and the tieDIE scores
	if tiedie_heat_scores:
		posteriorHeats = geomMean(linker_heats, tiedie_heat_scores)
		out = open(output_folder+"/"+sample_id+".NODE_SCORES.txt", 'w')
		for (key, val) in posteriorHeats.items():
			out.write(key+"\t"+str(val)+"\n")
		out.close()


	if subnet_soln is None or len(subnet_soln_nodes) < 2:
		print "No network found for sample:"+sample_id
		continue	

	# path validation logic...
	validator = BasicPathValidator({
		'source': mut_heats.keys(),
		'target': tf_heats.keys(),
		'source_actions': mut_signs,
		'target_actions': tf_signs})

	# search for consistent paths within this network solution
	subnet = Pathway(subnet_soln, validator=validator)
	filtered_edges = subnet.allPaths(mut_heats.keys(), tf_heats.keys(), 4)

	print "Writing network for sample "+sample_id
	writeNetwork(subnet_soln, output_folder+"/"+sample_id+".sif")
	writeEL(filtered_edges, output_folder+"/"+sample_id+".filtered.sif")

	# Node summary
	captured_source = subnet_soln_nodes.intersection(set(mutation_events))
	captured_target = subnet_soln_nodes.intersection(set(tf_events))
	
	if tiedie_heat_scores:
		ES_score, pval = ActivityScores.getEnrichmentScore(network, tiedie_heat_scores, subnet_soln_nodes)
		stats.write("\t".join([sample_id, str(ES_score), str(pval)])+"\n")
	
	if len(captured_source) == 0 or len(captured_target) == 0:
		print "No linking network found for sample:"+sample_id
		continue

	out = open(output_folder+"/"+sample_id+".txt", 'w')
	out.write("Source: "+"\t".join(captured_source)+"\n")
	out.write("Target: "+"\t".join(captured_target)+"\n")
	del linker_heats
	out.close()

stats.close()
out = open(output_folder+"/sample_heats.txt", 'w')
out.write("Sample\t"+"\t".join(features)+"\n")
for sample_id in sample_heats:
	out.write(sample_id+"\t"+"\t".join([str(sample_heats[sample_id][feature]) for feature in features])+"\n")
out.close()
