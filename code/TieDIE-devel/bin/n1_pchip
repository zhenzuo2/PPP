#!/usr/bin/env python

###
### n1_pchip: Script to map individual sample data onto a 'scaffold' network, yeilding a sample-specific
### network
###
### Authors:
###
###		Evan Paull (epaull@soe.ucsc.edu)
###		Joshua Stuart (jstuart@soe.ucsc.edu)
###
###
### Minimum Data Inputs: 
###		
###		arg 1 : sample_events: a text file with mutated or CNV altered events, one HUGO ID per line
###		arg 2 : sample_activities: activity z-scores for "Master Regulator" proteins in this patient. 
###		Can be generated with the VIPER algorithm, from RNA-Seq or microrarray. 
###
###		arg 3 :  a scaffold pathway in .sif format (geneA <interaction> geneB). Generated by the TieDIE algorithm
### 
### Optional:
###
###

import os, sys, re
from optparse import OptionParser
from random import sample
import numpy as np
parser = OptionParser()
parser.add_option("--pagerank",dest="pagerank",action="store_true", default=False, help="Use Personalized PageRank to Diffuse")
parser.add_option("--output",dest="output",action="store", default="n1_network")
(opts, args) = parser.parse_args()

sys.path.append(os.path.dirname(sys.argv[0])+'/../lib')
from kernel_scipy import SciPYKernel
from tiedie_util import *
from ppr import PPrDiffuser
from linkers import *

from collections import defaultdict

sys.stderr.write("Loading Scaffold Network..\n")
scaffold = parseNet(args[2])
scaffold_nodes = getNetworkNodes(scaffold)

if opts.pagerank:
	diffuser = PPrDiffuser(scaffold)
else:
	sys.stderr.write("Using SCIPY to compute the matrix exponential, t=0.1...\n")
	# No kernel supplied: use SCIPY to generate a kernel on the fly, and then use it
	# for subsequent diffusion operations
	diffuser = SciPYKernel(args[2])

# add heats for patient genomic events
input_heats_events = {}
for line in open(args[0], 'r'):
	input_heats_events[line.rstrip()] = 1
input_heats_events = normalizeHeats(input_heats_events)[0]
print ("Found :", str(len(input_heats_events)), " sample specific genomic events ")

# add heats for patient sample activities (or for 
input_heats_mrs = {}
for line in open(args[1], 'r'):
	input_heats_mrs[line.rstrip()] = 1
input_heats_mrs = normalizeHeats(input_heats_mrs)[0]
print ("Found :", str(len(input_heats_mrs.keys())), " master regulator / TF inputs")

print ("Diffusing input heats...")
events_diffused = diffuser.diffuse(input_heats_events)
mrs_diffused = diffuser.diffuse(input_heats_mrs)
# do a full TieDIE run: save heat values
# write the cytoscape output file
print "Running TieDIE with Standard Settings..."
input_heats = {'upstream': input_heats_events, 'downstream': input_heats_mrs }
diffused_heats = {'upstream': events_diffused, 'downstream': mrs_diffused }
subnet_soln, subnet_soln_nodes, linker_heats, cutoff = \
        extractSubnetwork(scaffold, input_heats, diffused_heats, 1.0, {})

n1_patient_network = subnet_soln
output_folder = opts.output
print ("Writing output network to ", output_folder)
writeNAfile(output_folder+"/heats.NA", linker_heats, "LinkerHeats")
writeHEATS(output_folder+"/heats.tab", linker_heats)
writeNetwork(subnet_soln, output_folder+"/n1_network.sif")

# write cytoscape input: label MRs
out = open(output_folder+"/n1_network.nodes.txt", 'w')
out.write('\t'.join(["node", "IsGenomicEvent", "IsMR"])+'\n')
events = input_heats_events.keys()
mrs = input_heats_mrs.keys()
for event in events:
	if event in mrs:
		out.write('\t'.join([event, "yes", "yes"])+'\n')
	else:
		out.write('\t'.join([event, "yes", "no"])+'\n')
for mr in mrs:
	if mr in events:
		continue
	out.write('\t'.join([mr, "no", "yes"])+'\n')

out.close()
print "done"

# randomly permute the upstream nodes, generate random networks as a background

input_heats = {'upstream': input_heats_events, 'downstream': input_heats_mrs }
diffused_heats = {'upstream': events_diffused, 'downstream': mrs_diffused }

edge_counts = defaultdict(float)
for i in range(0, 1000):

	# sample random upstream/genomic nodes
	rand_nodes = sample(scaffold_nodes, len(set(events).intersection(scaffold_nodes)))
	ih = {}
	for node in rand_nodes:
		ih[node] = 1

	# diffuse selected nodes, rerun tiedie
	input_heats['upstream'] = normalizeHeats(ih)[0]
	diffused_heats['upstream'] = diffuser.diffuse(input_heats_events)
	subnet_soln, subnet_soln_nodes, linker_heats, cutoff = \
        extractSubnetwork(scaffold, input_heats, diffused_heats, 1.0, {})

	print ("Random subnet node count"+str(len(subnet_soln_nodes)))
	for s in subnet_soln:
		for (i, t) in subnet_soln[s]:
			edge_counts[(s, i, t)] += 1.0/1000.0

out = open(output_folder+"/n1_rand_counts.txt", 'w')
for edge in edge_counts.keys():
	out.write('\t'.join(edge)+'\t'+str(edge_counts[edge])+'\n')
out.close()


##
## Remove frequently occuring edges from the real solution
##
out = open(output_folder+"/n1_minusNull.sif", 'w')
for s in n1_patient_network:
	for (i, t) in n1_patient_network[s]:
		if edge_counts[(s,i,t)] > 0.25:
			continue
		out.write('\t'.join([s, i, t])+'\n')
out.close()
